import streamlit as st
from google import genai
from google.genai import types, errors
import time
import os

# ==== ì„¤ì • ë¶€ë¶„ ====
api_key = os.getenv("GOOGLE_API_KEY")

if not api_key:
    st.error("í™˜ê²½ ë³€ìˆ˜ GOOGLE_API_KEYê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. (GOOGLE_API_KEY)")
    st.stop()

# ==== í´ë¼ì´ì–¸íŠ¸ & ìŠ¤í† ì–´ ====
@st.cache_resource
def get_client():
    return genai.Client(api_key=api_key)


@st.cache_resource
def get_store(display_name: str):
    """
    display_nameìœ¼ë¡œ Storeë¥¼ ì°¾ê³  ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±.
    (ì´ë¯¸ ë§Œë“¤ì–´ë‘” presto_* ìŠ¤í† ì–´ë„ display_name ê¸°ì¤€ìœ¼ë¡œ ì˜ ì°¾ì•„ì˜µë‹ˆë‹¤.)
    """
    client = get_client()
    for s in client.file_search_stores.list():
        if getattr(s, "display_name", None) == display_name:
            return s

    # ì—†ìœ¼ë©´ ìƒì„± (ì˜ˆì™¸ ì¼€ì´ìŠ¤ìš©)
    store = client.file_search_stores.create(
        config={"display_name": display_name}
    )
    return store


@st.cache_data(show_spinner=False)
def list_documents(store_name: str):
    """
    íŠ¹ì • File Search Store ì•ˆì— ë“¤ì–´ìˆëŠ” ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸ ì¡°íšŒ.
    ë°˜í™˜ê°’: documents ë¦¬ìŠ¤íŠ¸
    """
    client = get_client()
    docs = list(client.file_search_stores.documents.list(parent=store_name))
    return docs


def ask_question(
    store_name: str,
    history: list[types.Content],
    model_name: str,
) -> str:
    """File Searchê°€ ì—°ê²°ëœ Geminiì—ê²Œ ì§ˆë¬¸ (ì¬ì‹œë„ ë¡œì§ í¬í•¨)"""
    client = get_client()
    max_retries = 5
    delay = 2  # ì´ˆ

    for attempt in range(1, max_retries + 1):
        try:
            response = client.models.generate_content(
                model=model_name,
                contents=history,
                config=types.GenerateContentConfig(
                    system_instruction=(
                        "ë‹¹ì‹ ì€ ì œê³µëœ ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€í•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.\n"
                        "ë‹¤ìŒ ê·œì¹™ì„ ë°˜ë“œì‹œ ì¤€ìˆ˜í•˜ì„¸ìš”:\n"
                        "1. ì˜¤ì§ ì œê³µëœ ë¬¸ì„œ(Context)ì— ìˆëŠ” ë‚´ìš©ë§Œ ì‚¬ìš©í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”.\n"
                        "2. ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì€ 'ë¬¸ì„œì— í•´ë‹¹ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤'ë¼ê³  ë‹µë³€í•˜ê³ , ì™¸ë¶€ ì§€ì‹ì„ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.\n"
                        "3. ë‹µë³€ì˜ ëì—ëŠ” ë°˜ë“œì‹œ ì°¸ê³ í•œ ë¬¸ì„œì˜ ì´ë¦„(Source)ì„ ëª…ì‹œí•˜ì„¸ìš”.\n"
                        "   ì˜ˆì‹œ: (ì¶œì²˜: íŒŒì¼ëª….pdf)\n"
                        "4. ë‹µë³€ì€ ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ì„¸ìš”."
                    ),
                    tools=[
                        types.Tool(
                            file_search=types.FileSearch(
                                file_search_store_names=[store_name]
                            )
                        )
                    ]
                ),
            )
            return response.text or ""

        except errors.ServerError as e:
            # 503 ê°™ì€ ì„œë²„ ê³¼ë¶€í•˜ ì—ëŸ¬ë§Œ ì¬ì‹œë„
            if "overloaded" in str(e) and attempt < max_retries:
                print(
                    f"[ServerError] ê³¼ë¶€í•˜, {attempt}íšŒ ì‹œë„ ì‹¤íŒ¨ â†’ {delay}ì´ˆ í›„ ì¬ì‹œë„"
                )
                time.sleep(delay)
                continue

            st.error("í˜„ì¬ Gemini ì„œë²„ê°€ ê³¼ë¶€í•˜ ìƒíƒœì…ë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.")
            print("[ServerError ìµœì¢… ì‹¤íŒ¨]", e)
            return ""

        except errors.APIError as e:
            st.error(f"Gemini API ì—ëŸ¬ ë°œìƒ: {e}")
            print("[APIError]", e)
            return ""


# ==== Streamlit UI ====
st.set_page_config(page_title="Presto Knowledge AI Copilot", page_icon="ğŸ¤–", layout="wide")
st.title("ğŸ“˜ Presto Knowledge AI Copilot")

# --- ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” ---
if "history" not in st.session_state:
    st.session_state.history = []  # type: list[types.Content]

if "last_request_time" not in st.session_state:
    st.session_state.last_request_time = 0.0

MAX_TURNS = 6  # user+assistant ìŒ 6ê°œ ì •ë„ë©´ ì¶©ë¶„

# --- ì‚¬ì´ë“œë°”: ìŠ¤í† ì–´ / ëª¨ë¸ ì„ íƒ + íŒŒì¼ ë¦¬ìŠ¤íŠ¸ ---
st.sidebar.header("âš™ï¸ ì„¤ì •")

# 1) Store ì„ íƒ (í•œê¸€ ë¼ë²¨ â†” ì‹¤ì œ store display_name ë§¤í•‘)
store_options = {
    "[ê¸°ìˆ ]ì œí’ˆ": "presto_products",
    "[ê¸°ìˆ ]ì–´í”Œë¦¬ì¼€ì´ì…˜": "presto_applications",
    "[ê¸°ìˆ ]í”„ë¡œê·¸ë˜ë°": "presto_programmings",
    #"[íšŒì‚¬]ì‚¬ë‚´ê·œì •": "presto_regulations",
}

selected_label = st.sidebar.selectbox(
    "ğŸ“‚ Documentation Store ì„ íƒ",
    options=list(store_options.keys()),
    index=0,
)

store_display_name = store_options[selected_label]
store = get_store(store_display_name)

# 2) ëª¨ë¸ ì„ íƒ
model_name = st.sidebar.selectbox(
    "ğŸ§  Gemini ëª¨ë¸ ì„ íƒ",
    options=[
        "gemini-2.5-flash",        # ê¸°ë³¸ê°’ (ë¹ ë¥¸ ì‘ë‹µ)
        "gemini-2.5-pro",          # ì •í™•ë„/ì¶”ë¡ ë ¥ ìš°ì„ 
        "gemini-3-pro-preview",    # ìµœì‹  ë¯¸ë¦¬ë³´ê¸°
    ],
    index=0,
)

# 3) ì„ íƒëœ Store ì•ˆì˜ íŒŒì¼ ë¦¬ìŠ¤íŠ¸ í‘œì‹œ
st.sidebar.subheader("ğŸ“„ ì„ íƒëœ Storeì˜ íŒŒì¼ ëª©ë¡")

docs = list_documents(store.name)
if docs:
    for d in docs:
        display = getattr(d, "display_name", None) or getattr(d, "name", "(no name)")
        st.sidebar.markdown(f"- `{display}`")
else:
    st.sidebar.caption("ì•„ì§ ì´ Storeì—ëŠ” ë“±ë¡ëœ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")


# --- ë©”ì¸ ì˜ì—­ ì»¨í…Œì´ë„ˆ: ìœ„(ëŒ€í™”), ì•„ë˜(ì§ˆë¬¸ ë°•ìŠ¤) ---
chat_container = st.container()  # ëŒ€í™” í‘œì‹œìš© ì»¨í…Œì´ë„ˆ

if "history" not in st.session_state:
    st.session_state.history = []  # type: list[types.Content]

if "last_request_time" not in st.session_state:
    st.session_state.last_request_time = 0.0

MAX_TURNS = 6  # user+assistant ìŒ 6ê°œ ì •ë„ë©´ ì¶©ë¶„


def render_history_compact():
    """ìƒˆ ì§ˆë¬¸ì´ ì—†ì„ ë•Œ: ê³¼ê±° ëŒ€í™”ëŠ” ì ‘ê³ , ë§ˆì§€ë§‰ ëŒ€í™”ë§Œ í¼ì³ì„œ ë³´ì—¬ì¤€ë‹¤."""
    history = st.session_state.history
    pairs = len(history) // 2

    if pairs == 0:
        return

    with chat_container:
        if pairs == 1:
            user_msg = history[0]
            model_msg = history[1]
            with st.chat_message("user"):
                st.markdown(user_msg.parts[0].text)
            with st.chat_message("assistant"):
                st.markdown(model_msg.parts[0].text)
        else:
            # ì´ì „ ëŒ€í™”ë“¤: expanderë¡œ ì ‘ê¸°
            for i in range(pairs - 1):
                user_msg = history[2 * i]
                model_msg = history[2 * i + 1]
                title = user_msg.parts[0].text.strip().replace("\n", " ")
                if len(title) > 30:
                    title = title[:27] + "..."
                with st.expander(f"ëŒ€í™” {i+1}: {title}", expanded=False):
                    with st.chat_message("user"):
                        st.markdown(user_msg.parts[0].text)
                    with st.chat_message("assistant"):
                        st.markdown(model_msg.parts[0].text)

            # ë§ˆì§€ë§‰(ê°€ì¥ ìµœê·¼) ëŒ€í™”ëŠ” ê·¸ëŒ€ë¡œ í¼ì³ì„œ ë³´ì—¬ì£¼ê¸°
            last_user = history[-2]
            last_model = history[-1]
            with st.chat_message("user"):
                st.markdown(last_user.parts[0].text)
            with st.chat_message("assistant"):
                st.markdown(last_model.parts[0].text)



st.markdown("---")

user_input = st.chat_input(
    placeholder="ğŸ’¬ ì§ˆë¬¸ì„ ì…ë ¥í•´ ì£¼ì„¸ìš” (Enterë¡œ ì§ˆë¬¸ ë³´ë‚´ê¸°)"
)

if user_input:
    now = time.time()

    # ìš”ì²­ ê°„ê²© ì œí•œ
    if now - st.session_state.last_request_time < 1.5:
        st.session_state.last_request_time = now
        # ê¸°ì¡´ ëŒ€í™”ëŠ” ì ‘ì–´ì„œ ë³´ì—¬ì£¼ê³  ê²½ê³ 
        render_history_compact()
        with chat_container:
            st.warning("ìš”ì²­ ê°„ê²©ì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
    else:
        st.session_state.last_request_time = now

        # ìƒˆ user ë©”ì‹œì§€ êµ¬ì„±
        user_msg = types.Content(
            role="user",
            parts=[types.Part(text=user_input)]
        )
        temp_history = st.session_state.history + [user_msg]

        # ì±„íŒ… ì˜ì—­: ê³¼ê±° ëŒ€í™”ëŠ” expander, ìƒˆ ì§ˆë¬¸/ë‹µë³€ì€ í¼ì³ì„œ
        with chat_container:
            history = st.session_state.history
            pairs = len(history) // 2

            # ì´ì „ ëŒ€í™” expanderë¡œ ì ‘ê¸°
            for i in range(pairs):
                prev_user = history[2 * i]
                prev_model = history[2 * i + 1]
                title = prev_user.parts[0].text.strip().replace("\n", " ")
                if len(title) > 30:
                    title = title[:27] + "..."
                with st.expander(f"ëŒ€í™” {i+1}: {title}", expanded=False):
                    with st.chat_message("user"):
                        st.markdown(prev_user.parts[0].text)
                    with st.chat_message("assistant"):
                        st.markdown(prev_model.parts[0].text)

            # ì´ë²ˆì— ë³´ë‚¸ user ë©”ì‹œì§€
            with st.chat_message("user"):
                st.markdown(user_input)

            # assistant ë‹µë³€ + spinner
            with st.chat_message("assistant"):
                with st.spinner("ìƒê° ì¤‘..."):
                    answer = ask_question(store.name, temp_history, model_name)

                if answer:
                    st.markdown(answer)
                else:
                    answer = "âš ï¸ ì‘ë‹µì„ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. (ì„œë²„ ê³¼ë¶€í•˜ ë˜ëŠ” API ì—ëŸ¬)"
                    st.markdown(answer)

        # history ì—…ë°ì´íŠ¸
        st.session_state.history.append(user_msg)
        model_msg = types.Content(
            role="model",
            parts=[types.Part(text=answer)]
        )
        st.session_state.history.append(model_msg)

        # íˆìŠ¤í† ë¦¬ê°€ ë„ˆë¬´ ê¸¸ì–´ì§€ë©´ ë’¤ì—ì„œ Ní„´ë§Œ ë‚¨ê¸°ê¸°
        if len(st.session_state.history) > MAX_TURNS * 2:
            st.session_state.history = st.session_state.history[-MAX_TURNS * 2:]
else:
    # ìƒˆ ì§ˆë¬¸ì´ ì—†ìœ¼ë©´ compact ë Œë”ë§ë§Œ
    render_history_compact()
